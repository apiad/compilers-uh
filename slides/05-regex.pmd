% Expresiones Regulares
% MSc. Alejandro Piad Morffis
% MatCom, UH (CC BY-SA-NC 4.0)

# Volvamos al problema original

Para parsear el texto de entrada:

    let x=read() in 2*(x+5)

El primer paso es convertir a una secuencia de tokens:

    let x = read ( ) in 2 * ( x + 5 )

# ¿Qué son los tokens?

. . .

```python
class Token:
    def __init__(self, line, column, type, lexeme):
        self.line = line
        self.column = column
        self.type = type
        self.lexeme = lexeme

>>> tokenize("let x=read() in 2*(x+5)")
[
    Token(line=1,column=1,type="let",lexeme="let"),
    # ...
    Token(line=1,column=5,type="id",lexeme="x"),
    # ...
    Token(line=1,column=16,type="number",lexeme="2"),
    # ...
]



#
```

# ¿Por qué tokenizar?

. . .

Para simplicar la gramática:

- Normalizar los literales, identificadores, etc.
- Eliminar los espacios en blanco innecesarios.
- Eliminar los comentarios.
- Reemplazar caracteres especiales.
- Lidiar con los detalles del _encoding_.
- Detectar errores léxicos (e.j. `string` incompletos).

# Haciendo un tokenizador

. . .

¿Podemos hacer una gramática LL para los tokens?

    digit   -> '0' | '1' |...| '9'
    number  -> digit | digit number
    char    -> 'a' | ... | 'z' | 'A' | ...
    alpha   -> char alpha | num alpha | epsilon
    id      -> char alpha
    ...
    lparen  -> '('
    rparen  -> ')'
    oper    -> '*' | '/' | '-' | '+'
    ...
    let     -> 'l' 'e' 't'
    ...
    ws      -> ' ' | '\t' | '\n'
    comment -> ...


# ¿Qué problemas tiene este enfoque?

. . .

- ¿Cuántos tokens tienen prefijos comunes?
- ¿Qué tamaño tendrá el árbol de derivación?
- ¿Cómo son las reglas semánticas de cada token?
- ¿Cómo logro el comportamiento _greedy_?
- ¿Podemos resolverlo con _menos_ que LL?

# Tokenizando a mano

    Input:  |l e t  x = r e a d ( )  i n  2 * ( x + 5 )
    Token:
    Output:

# Tokenizando a mano

    Input:   l|e t  x = r e a d ( )  i n  2 * ( x + 5 )
    Token:   l
    Output:

# Tokenizando a mano

    Input:   l e|t  x = r e a d ( )  i n  2 * ( x + 5 )
    Token:   le
    Output:

# Tokenizando a mano

    Input:   l e t| x = r e a d ( )  i n  2 * ( x + 5 )
    Token:   let
    Output:

# Tokenizando a mano

    Input:   l e t |x = r e a d ( )  i n  2 * ( x + 5 )
    Token:
    Output:  let

# Tokenizando a mano

    Input:   l e t  x|= r e a d ( )  i n  2 * ( x + 5 )
    Token:   x
    Output:  let

# Tokenizando a mano

    Input:   l e t  x =|r e a d ( )  i n  2 * ( x + 5 )
    Token:   =
    Output:  let x

# Tokenizando a mano

    Input:   l e t  x = r|e a d ( )  i n  2 * ( x + 5 )
    Token:   r
    Output:  let x =

# Tokenizando a mano

    Input:   l e t  x = r e|a d ( )  i n  2 * ( x + 5 )
    Token:   re
    Output:  let x =

# Tokenizando a mano

    Input:   l e t  x = r e a|d ( )  i n  2 * ( x + 5 )
    Token:   rea
    Output:  let x =

# Tokenizando a mano

    Input:   l e t  x = r e a d|( )  i n  2 * ( x + 5 )
    Token:   read
    Output:  let x =

# Tokenizando a mano

    Input:   l e t  x = r e a d (|)  i n  2 * ( x + 5 )
    Token:   (
    Output:  let x = read

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )| i n  2 * ( x + 5 )
    Token:   )
    Output:  let x = read (

# Tokenizando a mano

    Input:   l e t  x = r e a d ( ) |i n  2 * ( x + 5 )
    Token:
    Output:  let x = read ( )

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )  i|n  2 * ( x + 5 )
    Token:   i
    Output:  let x = read ( )

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )  i n| 2 * ( x + 5 )
    Token:   in
    Output:  let x = read ( )

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )  i n |2 * ( x + 5 )
    Token:
    Output:  let x = read ( ) in

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )  i n  2|* ( x + 5 )
    Token:   2
    Output:  let x = read ( ) in

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )  i n  2 *|( x + 5 )
    Token:   *
    Output:  let x = read ( ) in 2

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )  i n  2 * (|x + 5 )
    Token:   (
    Output:  let x = read ( ) in 2 *

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )  i n  2 * ( x|+ 5 )
    Token:   x
    Output:  let x = read ( ) in 2 * (

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )  i n  2 * ( x +|5 )
    Token:   +
    Output:  let x = read ( ) in 2 * ( x

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )  i n  2 * ( x + 5|)
    Token:   5
    Output:  let x = read ( ) in 2 * ( x +

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )  i n  2 * ( x + 5 )|
    Token:   )
    Output:  let x = read ( ) in 2 * ( x + 5

# Tokenizando a mano

    Input:   l e t  x = r e a d ( )  i n  2 * ( x + 5 )|
    Token:
    Output:  let x = read ( ) in 2 * ( x + 5 )

# Haciendo un tokenizador v2.0

. . .

```python
def tokenize(input):
    state = 0
    curr = ""
    for c in input:
        if state == 0:    # None
            if c.isalpha():
                curr += c
                state = 1 # id | keyword
            elif c.isdigit():
                curr += c
                state = 2 # constante
            # ...
        if state == 1:    # id | keyword
            if c.isspace() or c in oper:
                if curr == 'let':
                    yield Token(type='let', ...)
                    # ...
```

# Automatizando este proceso

Tendremos 2 componentes fundamentales:

- Una componente _declarativa_, de "alto nivel" para definir cómo lucen sintácticamente los tokens.

- Una componente _procedural_, de "bajo nivel" que reconocerá automáticamente los tokens.

Y como ya es usual, diseñaremos un mecanismo para convertir de "alto nivel" a "bajo nivel".

# Expresiones regulares

Una expresión regular es una definición recursiva de un lenguaje:

- $a$ es la expresión regular para $L(a) = \{ a \}$
- $\epsilon$ es la expresión regular para $L(\epsilon) = \{ \epsilon \}$

Si $s$ y $r$ son expresiones regulares, entonces:

- **Unión**: $(s)|(r)$ es la expresión regular para el lenguaje $L(s) \bigcup L(r)$.
- **Concatenación**: $(s)(r)$ es la expresión regular para el lenguaje $L(s)L(r)$.
- **Clausura**: $(s)*$ es la expresión regular para el lenguaje $L(s)* = \bigcup_{k=0}^\infty L(s)^k$.

Un lenguaje definido de esta forma, le llamaremos **lenguaje regular**.
Más adelante caracterizaremos formalmente a estos lenguajes.

# Ejemplos

> - $(a|b)*$
> - $aa(a|b)*$
> - $(a|b)*bb$
> - $a*(baa*)*(b|\epsilon)$
> - $(1|2|3|4|5|6|7|8|9)(0|1|2|3|4|5|6|7|8|9)*$

# Expresiones regulares extendidas

Sin cambiar la definición, podemos adicionar algunos operadores cómodos:

- **Opciones:** $[abc]$ será equivalente a $(a|b|c)$.
- **Rango:** $[a-z]$ (o cualquier otro rango sensible) será equivalente por $(a|b|...|z)$.
- **Cero o una vez:** $(s)?$ será equivalente a $(s)|\epsilon$.
- **Clausura positiva:** $(s)+$ será equivalente a $(s)(s)*$.

Además diremos que $*$ y $+$ tienen la mayor prioridad, y $|$ la menor y asocia a la izquierda.

**NOTA:** Al adicionar estos operadores no hemos cambiado la definición (ni el poder expresivo), luego toda demostración formal la podemos realizar solo con la definición original si es más cómodo.

# El lenguaje de los tokens

Ahora podemos definir el lenguaje de los tokens más fácilmente:

$$
\begin{array}{r@{\,\,\rightarrow\,\,}l}
id     & [a-zA-Z][a-zA-Z0-9]* \\
num    & [1-9][0-9]*(.[0-9]+)? \\
oper   & [*/+-] \\
lparen & \backslash( \\
rparen & \backslash) \\
equals & = \\
let    & \textrm{let} \\
in     & \textrm{in} \\
\end{array}
$$

# Demostrando equivalencias entre lenguajes

Si tenemos una expresión regular $r$ y un lenguaje $L$, ¿cómo demostrar que $L(r) = L$?

- $L(r) \subseteq L$: simulando la expresión regular, demostrar que sólo reconoce cadenas correctas.
- $L \subseteq L(r)$: dar una forma de construir cada cadena de $L$.
- Apoyarse en cada sub-expresión $s$ de $r$ genera un sub-lenguaje $L(s)$, y construir recursivamente $L$ aplicando las propiedades.

### Ejemplo:

- $a*(baa*)*(b|\epsilon)$

# Gramáticas regulares

Una **gramática regular** es una gramática $G=<T,N,P,S>$ donde todas las producciones tienen la forma:

- $A \,\, \rightarrow \,\, a B$
- $A \,\, \rightarrow \,\, a$
- $A \,\, \rightarrow \,\, \epsilon$

Siendo $a \in T$ un terminal y $A,B \in N$ no-terminales.

### Ejemplo

$$
\begin{array}{r@{\,\,\rightarrow\,\,}l}
S & a S \,\,|\,\, bA \,\,|\,\, \epsilon \\
A & aS \\
\end{array}
$$

# Algunos comentarios

Las expresiones regulares son la navaja suiza del procesamiento de texto:

- Buscar y reemplazar en archivos.
- Validar entradas en formularios.
- Extraer patrones en lenguaje casi natural.
- Syntax-highlight en editores de texto.
- ...
